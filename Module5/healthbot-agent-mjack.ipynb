{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b4591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These should already be installed on your workspace\n",
    "!pip install --disable-pip-version-check --quiet -U langchain==0.2.16\n",
    "!pip install --disable-pip-version-check --quiet -U langchain_openai==0.1.23\n",
    "!pip install --disable-pip-version-check --quiet -U langgraph==0.2.19\n",
    "!pip install --disable-pip-version-check --quiet -U langchainhub==0.1.21\n",
    "!pip install --disable-pip-version-check --quiet -U tavily-python==0.4.0\n",
    "!pip install --disable-pip-version-check --quiet -U langchain-community==0.2.16\n",
    "!pip install --disable-pip-version-check --quiet -U python-dotenv==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T15:39:53.914515Z",
     "start_time": "2024-09-25T15:39:53.907761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load in the OpenAI key and Tavily key.\n",
    "# In the project folder, create a file named 'config.env'\n",
    "# ensure your .env file contains keys named OPENAI_API_KEY=\"your key\" and TAVILY_API_KEY=\"your key\"\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('config.env')\n",
    "assert os.getenv('OPENAI_API_KEY') is not None\n",
    "assert os.getenv('TAVILY_API_KEY') is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ac680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from typing import Dict, List, Literal\n",
    "\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import MessagesState, add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14838f48",
   "metadata": {},
   "source": [
    "## Instantiate Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    "    streaming=True,\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05271173",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_client = TavilyClient(\n",
    "    api_key=os.getenv(\"TAVILY_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab7216",
   "metadata": {},
   "source": [
    "## Define State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f281d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    patient_question: str\n",
    "    answer: str\n",
    "    summary: str\n",
    "    quiz_requested: str = \"NO\"\n",
    "    quiz_question: str\n",
    "    quiz_response: str\n",
    "    graded_result: str\n",
    "    new_topic_requested: str = \"NO\"\n",
    "    # config: RunnableConfig = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03adc8a",
   "metadata": {},
   "source": [
    "## Create Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f572a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_text_to_user(text: str):\n",
    "    print()\n",
    "    pprint(text)\n",
    "    print()\n",
    "    time.sleep(2) # wait for it to render before asking for input or it'll never show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba630eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_messages(messages: MessagesState):\n",
    "    print()\n",
    "    for message in messages:\n",
    "        message.pretty_print()\n",
    "    time.sleep(2) # wait for it to render before asking for input or it'll never show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12beccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_user_for_input(input_description)->Dict:\n",
    "    response = input(input_description)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14594ae",
   "metadata": {},
   "source": [
    "## Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb3777",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def web_search(question:str)->Dict:\n",
    "    \"\"\"\n",
    "    Return top search results for a given search query\n",
    "    \"\"\"\n",
    "    response = tavily_client.search(question)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0bc66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [web_search]\n",
    "tools_by_name = {tool.name: tool for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22faf2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7f6e74",
   "metadata": {},
   "source": [
    "## Define Nodes and Routers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ebc812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool node:\n",
    "def web_search_node(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        content = str(observation['results'])\n",
    "        tool_call_id = tool_call[\"id\"]\n",
    "        messages.append(ToolMessage(content=content, tool_call_id=tool_call_id))\n",
    "\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be986ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent nodes:\n",
    "def entry_point(state: State):\n",
    "    # thread_id = THREADID\n",
    "    # config = RunnableConfig(recursion_limit=2000, configurable={\"thread_id\": thread_id})\n",
    "\n",
    "    text = \"Hello. How are you doing today?\"\n",
    "    display_text_to_user(text)\n",
    "\n",
    "    system_message = SystemMessage(\"You are an experienced medical professional. \"\n",
    "                                   \"You conduct a web search to respond to a user's question.\")\n",
    "    messages = [system_message]\n",
    "    # return {\"messages\": messages, \"config\": config}\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "\n",
    "def ask_health_topic(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    input_description = \"What is your health-related question? Please type a question on a health topic or a medical treatment. \"\n",
    "    human_input = ask_user_for_input(input_description)\n",
    "\n",
    "    human_message = HumanMessage(\n",
    "                    \"Perform a web search to answer the following question: \"\n",
    "                    f\"```{human_input}```\"\n",
    "                    \"Use the appropriate tool and conduct the web research for this question. \"\n",
    "                    \"Return a detailed response including health topic, medical condition, treatment options, post-treatment care, \"\n",
    "                    \"and important citations from the medical literature or medical news outlets.\"\n",
    "                    )\n",
    "    messages.append(human_message)\n",
    "\n",
    "    # print()\n",
    "    # print(\"ask_health_topic:\")\n",
    "    # display_messages(messages)\n",
    "\n",
    "    return {\n",
    "        \"patient_question\": human_input,\n",
    "        \"messages\": messages,\n",
    "        }\n",
    "\n",
    "\n",
    "def perform_websearch(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # if state[\"config\"]:\n",
    "    #     ai_message = llm_with_tools.invoke(messages, config=state[\"config\"])\n",
    "    # else:\n",
    "    #     ai_message = llm_with_tools.invoke(messages)\n",
    "\n",
    "    ai_message = llm_with_tools.invoke(messages)\n",
    "    messages.append(ai_message)\n",
    "\n",
    "    # print()\n",
    "    # print(\"perform_websearch:\")\n",
    "    # display_messages(messages)\n",
    "\n",
    "    return {\"messages\": messages, \"answer\": ai_message.content}\n",
    "\n",
    "\n",
    "def summarize_search(state: State):\n",
    "    answer = state[\"answer\"]\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"system\", \"You are an excellent medical writer who can summarize complex medical topics \\n\"\n",
    "               \"into easy to understand language that a layman, i.e. somebody who is not a medical expert, can understand \\n\"\n",
    "               \"so they can make appropriate decisions for their health with the information provided by you.\"),\n",
    "    (\"human\", \"Create a concise summary of the provided {answer} for patients \\n\"\n",
    "              \"that are not medical experts. \\n\"\n",
    "              \"Create nicely formatted, easily readable text as output \\n\"\n",
    "              \"with several sections with the headers 'health topic', 'medical condition', 'treatment options', 'post-treatment care' and 'citations'. \\n\"\n",
    "              \"'health topic': a short description of health topic being discussed, \\n\"\n",
    "              \"'medical condition': a description of the medical condition, \\n\"\n",
    "              \"'treatment options': a brief discussion of several treatment options, \\n\"\n",
    "              \"'post-treatment care': a listing of recommended patient activities during post-treatment care, \\n\"\n",
    "              \"'citations': include relevant citations from the literature and important medical news outlets if appropriate. \\n\"\n",
    "    ),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    chain = template | llm_with_tools | StrOutputParser()\n",
    "\n",
    "    ai_message = chain.invoke({\"answer\": answer})\n",
    "    messages.append(ai_message)\n",
    "\n",
    "    # print()\n",
    "    # print(\"summarize_search output:\")\n",
    "    # display_messages(messages)\n",
    "\n",
    "    return {\"messages\": messages, \"summary\": ai_message}\n",
    "\n",
    "\n",
    "def present_summary(state: State):\n",
    "    display_text_to_user(state[\"summary\"])\n",
    "\n",
    "\n",
    "def check_quiz_request(state: State):\n",
    "    input_description = \"Do you want to check your comprehension based on a generated quiz? (YES or NO)\"\n",
    "    human_input = ask_user_for_input(input_description)\n",
    "    return {\"quiz_requested\": human_input}\n",
    "\n",
    "\n",
    "def create_quiz(state: State):\n",
    "    summary = state[\"summary\"]\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"system\", \"You are an experienced medical educator and experienced in the creation of medical exams.\"),\n",
    "    (\"human\", \"Generate a single, relevant quiz question based on the provided information {summary} .\"\n",
    "              \"Create a quiz question that expects a comprehensive answer in 3 to 4 sentences as a response. \"\n",
    "              \"Create a quiz question that tests knowledge and understanding of \"\n",
    "              \"a medical condition, a treatment option, or of a post-treatment care. \"\n",
    "              \"Do not create a multiple-choice quiz. Do not show the solution. \"\n",
    "    ),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    chain = template | llm_with_tools | StrOutputParser()\n",
    "\n",
    "    ai_message = chain.invoke({\"summary\": summary})\n",
    "    messages.append(ai_message)\n",
    "\n",
    "    # print()\n",
    "    # print(\"create_quiz:\")\n",
    "    # display_messages(messages)\n",
    "\n",
    "    return {\"messages\": messages, \"quiz_question\": ai_message}\n",
    "\n",
    "\n",
    "def present_quiz(state: State):\n",
    "    text=(\"Please answer following quiz question on the health topic.\"\n",
    "          \"Please answer in about 3 to 4 sentences in a comprehensive response to the question.\"\n",
    "          \"Please type your answer in the box provided and hit RETURN:\")\n",
    "    display_text_to_user(text)\n",
    "\n",
    "    quiz_question = state[\"quiz_question\"]\n",
    "    human_input = ask_user_for_input(quiz_question)\n",
    "    return {\"quiz_response\": human_input}\n",
    "\n",
    "\n",
    "def grade_quiz(state: State):\n",
    "    quiz_response = state[\"quiz_response\"]\n",
    "    quiz_question = state[\"quiz_question\"]\n",
    "    summary = state[\"summary\"]\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"system\", \"You are an expert educator with medical expertise tasked with grading a student's answer to a quiz question..\"),\n",
    "    (\"human\",  '''Evaluate the response {quiz_response} carefully and assign a letter grade (A, B, C, D, or F)\n",
    "                  along with a detailed explanation.\n",
    "\n",
    "                    ## Input Format\n",
    "                    - **Question:** [The original quiz question] {quiz_question}\n",
    "                    - **Summary:** [Summary on the health topic] {summary}\n",
    "                    - **Student's Response:** [The student's submitted answer] {quiz_response}\n",
    "\n",
    "                    ## Grading Criteria\n",
    "\n",
    "                    Evaluate based on the following dimensions:\n",
    "\n",
    "                    1. **Accuracy (40%)** - Is the information factually correct?\n",
    "                    2. **Completeness (30%)** - Does it address all parts of the question?\n",
    "                    3. **Understanding (20%)** - Does it demonstrate comprehension of underlying concepts?\n",
    "                    4. **Clarity (10%)** - Is it well-organized and clearly communicated?\n",
    "\n",
    "                    ## Grading Scale\n",
    "\n",
    "                    - **A (90-100%):** Exceptional. Accurate, complete, demonstrates deep understanding, well-articulated.\n",
    "                    - **B (80-89%):** Good. Mostly accurate and complete with minor gaps or unclear points.\n",
    "                    - **C (70-79%):** Satisfactory. Basic understanding but missing key elements or contains some errors.\n",
    "                    - **D (60-69%):** Poor. Significant gaps, multiple errors, or fundamental misunderstandings.\n",
    "                    - **F (<60%):** Failing. Incorrect, incomplete, or demonstrates lack of understanding.\n",
    "\n",
    "                    ## Output Format\n",
    "\n",
    "                    **Grade:** [Letter Grade]\n",
    "\n",
    "                    **Explanation:**\n",
    "                    - **Strengths:** [What the student did well]\n",
    "                    - **Weaknesses:** [What was missing, incorrect, or unclear]\n",
    "                    - **Key Missing Elements:** [Specific points from the expected answer that were omitted]\n",
    "                    - **Suggestions for Improvement:** [Constructive feedback]\n",
    "\n",
    "                    **Overall Assessment:** [5 to 6 sentence summary justifying the grade]\n",
    "\n",
    "                  Steps:\n",
    "                  - Generate a solution for the {quiz_question} from the {summary} in 3 to 4 sentences.\n",
    "                    Print your solution titled with 'AI response:'.\n",
    "                  - Then show the grade for the student's response {quiz_response} to the question {quiz_question}\n",
    "                    titled with 'Grade:' and an explanation for your grading titled with 'Explanation of Grading:'.\n",
    "                  - Be fair, constructive, and specific in your evaluation. Focus on helping the student understand\n",
    "                    where they succeeded and where they can improve.\n",
    "                  - Include relevant citations of the {summary} at the end of the explanation.\n",
    "                  '''\n",
    "    ),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    chain = template | llm_with_tools | StrOutputParser()\n",
    "\n",
    "    ai_message = chain.invoke({\n",
    "        \"quiz_response\": quiz_response,\n",
    "        \"quiz_question\": quiz_question,\n",
    "        \"summary\": summary,\n",
    "        }\n",
    "    )\n",
    "    messages.append(ai_message)\n",
    "\n",
    "    # print()\n",
    "    # print(\"grade_quiz:\")\n",
    "    # display_messages(messages)\n",
    "\n",
    "    return {\"messages\": messages, \"graded_result\": ai_message}\n",
    "\n",
    "\n",
    "def present_grade(state: State):\n",
    "    display_text_to_user(\"Here is your graded result: \")\n",
    "    display_text_to_user(state[\"graded_result\"])\n",
    "\n",
    "\n",
    "def check_new_topic(state: State):\n",
    "    input_description = \"Do you want to ask another question about another health-related topic? (YES or NO):\"\n",
    "    human_input = ask_user_for_input(input_description)\n",
    "    return {\"new_topic_requested\": human_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ff5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# router funtions:\n",
    "def tool_router(state: MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"web_search\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def check_quiz_request_router(state: State):\n",
    "    quiz_requested = state[\"quiz_requested\"]\n",
    "    if quiz_requested.lower() == \"yes\":\n",
    "        return \"create_quiz\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def check_new_topic_router(state: State):\n",
    "    new_topic_requested = state[\"new_topic_requested\"]\n",
    "    if new_topic_requested.lower() == \"yes\":\n",
    "        # new_thread_id = THREADID + 1\n",
    "        # state[\"config\"] = RunnableConfig(recursion_limit=2000, configurable={\"thread_id\": new_thread_id})\n",
    "        return \"ask_health_topic\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5811f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81592802",
   "metadata": {},
   "source": [
    "## Create Workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d64ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ecb72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"entry_point\", entry_point)\n",
    "workflow.add_node(\"ask_health_topic\", ask_health_topic)\n",
    "workflow.add_node(\"perform_websearch\", perform_websearch)\n",
    "\n",
    "# workflow.add_node(\"web_search\", ToolNode([web_search]))\n",
    "workflow.add_node(\"web_search\", web_search_node)\n",
    "\n",
    "workflow.add_node(\"summarize_search\", summarize_search)\n",
    "workflow.add_node(\"present_summary\", present_summary)\n",
    "workflow.add_node(\"check_quiz_request\", check_quiz_request)\n",
    "workflow.add_node(\"create_quiz\", create_quiz)\n",
    "workflow.add_node(\"present_quiz\", present_quiz)\n",
    "workflow.add_node(\"grade_quiz\", grade_quiz)\n",
    "workflow.add_node(\"present_grade\", present_grade)\n",
    "workflow.add_node(\"check_new_topic\", check_new_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_edge(START, \"entry_point\")\n",
    "workflow.add_edge(\"entry_point\", \"ask_health_topic\")\n",
    "workflow.add_edge(\"ask_health_topic\", \"perform_websearch\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    source=\"perform_websearch\",\n",
    "    path=tool_router,\n",
    "    path_map=[\"web_search\", END]\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"perform_websearch\")\n",
    "\n",
    "workflow.add_edge(\"perform_websearch\", \"summarize_search\")\n",
    "workflow.add_edge(\"summarize_search\", \"present_summary\")\n",
    "workflow.add_edge(\"present_summary\", \"check_quiz_request\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    source=\"check_quiz_request\",\n",
    "    path=check_quiz_request_router,\n",
    "    path_map=[\"create_quiz\", END]\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"create_quiz\", \"present_quiz\")\n",
    "workflow.add_edge(\"present_quiz\", \"grade_quiz\")\n",
    "workflow.add_edge(\"grade_quiz\", \"present_grade\")\n",
    "workflow.add_edge(\"present_grade\", \"check_new_topic\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    source=\"check_new_topic\",\n",
    "    path=check_new_topic_router,\n",
    "    path_map=[\"ask_health_topic\", END]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78fdd13",
   "metadata": {},
   "source": [
    "## Display Workflow and Add Memory Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "graph = workflow.compile(\n",
    "            checkpointer=memory,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4086533",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eda4421",
   "metadata": {},
   "source": [
    "## Run Initial Workflow\n",
    "\n",
    "Example human input when AI asks:\n",
    "\n",
    "'What are treatment methods for skin melanoma?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f64de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "THREADID=1\n",
    "config = RunnableConfig(recursion_limit=2000, configurable={\"thread_id\": THREADID})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a0037",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_question = {\"patient_question\": \"\"}\n",
    "# input_question = {\"question\": \"What are treatment methods for skin melanoma?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f6f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for event in graph.stream(\n",
    "#     input=input_question,\n",
    "#     config=config,\n",
    "#     stream_mode=\"values\"\n",
    "#     ):\n",
    "#     if not event['messages']:\n",
    "#         continue\n",
    "#     event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e5f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = graph.invoke(\n",
    "    input=input_question,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"patient_question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5fdd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9da8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327610c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"quiz_requested\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cbd553",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output[\"quiz_requested\"] == \"yes\":\n",
    "    print(output[\"quiz_question\"])\n",
    "    print(output[\"quiz_response\"])\n",
    "    print(output[\"graded_result\"])\n",
    "    print(output[\"new_topic_requested\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa9a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in output[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda38bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a96ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_agenticai_udemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
